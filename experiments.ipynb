{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "089f6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b423de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/lustre/dtlake01/aramis/users/sasha.collin/miniconda3/envs/venv/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "import clinicadl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import log_loss\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from math import floor\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# clinicaDL\n",
    "from clinicadl.tools.tsv.data_split import create_split\n",
    "from clinicadl.tools.deep_learning.data import generate_sampler, return_dataset, MRIDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from clinicadl.tools.deep_learning.cnn_utils import train, get_criterion, test\n",
    "from clinicadl.tools.deep_learning.models.random import RandomArchitecture\n",
    "from clinicadl.tools.deep_learning import EarlyStopping\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualization\n",
    "from scipy.ndimage import zoom\n",
    "import itkwidgets\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d32fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73f81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.explanations.evaluation import *\n",
    "from tools.explanations.GradCam import *\n",
    "from tools.explanations.guided_backprop import *\n",
    "from train.train_CNN import *\n",
    "from tools.callbacks import *\n",
    "from tools.data import *\n",
    "from tools.explanations.visualization import *\n",
    "from tools.models.CN5_FC3_3D import *\n",
    "from tools.settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29293b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021.tsv'\n",
    "summary_path = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021_summary.tsv'\n",
    "# df_data = pd.read_csv(data_path,sep='\\t',nrows=10)\n",
    "# df_summary = pd.read_csv(summary_path,sep='\\t',nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61834a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name='t1-volume'\n",
    "atlas_id='AAL2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb619243",
   "metadata": {},
   "source": [
    "# Train Single CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e3401",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67523b0",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2bcfac46448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcaps_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# global parameters\n",
    "caps_directory = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021/'\n",
    "batch_size = 16\n",
    "num_workers = os.cpu_count()\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac0b65",
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataframes\n",
    "AD = pd.read_csv('subjects/AD.tsv',sep='\\t')\n",
    "CN = pd.read_csv('subjects/CN.tsv',sep='\\t')\n",
    "\n",
    "# remove samples with NaN\n",
    "AD.drop(AD[AD.isna().sum(axis=1) > 0].index, inplace=True)\n",
    "CN.drop(CN[CN.isna().sum(axis=1) > 0].index, inplace=True)\n",
    "\n",
    "# split data between training and validation sets\n",
    "training_df, valid_df = create_split('AD', AD, 'diagnosis',0.2)\n",
    "df_CN = create_split('CN', CN, 'diagnosis',0.2)\n",
    "training_df = training_df.append(df_CN[0]).reset_index().iloc[np.array([0,1,2,-1,-2,-3])]\n",
    "valid_df = valid_df.append(df_CN[1]).reset_index().iloc[np.array([0,1,2,-1,-2,-3])]\n",
    "\n",
    "# drop index column\n",
    "training_df.drop(columns = ['index'], inplace=True)\n",
    "valid_df.drop(columns = ['index'], inplace=True)\n",
    "\n",
    "train_transforms, all_transforms = get_transforms('image', minmaxnormalization=True, data_augmentation=None )\n",
    "# fetch volumetric data\n",
    "stds, df_add_data = fetch_add_data(training_df)\n",
    "\n",
    "# all_transforms = torchvision.transforms.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa898c26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_train = MRIDatasetImage(caps_directory, training_df, df_add_data=df_add_data,all_transformations=all_transforms) #train_transformations=all_transforms\n",
    "data_valid = MRIDatasetImage(caps_directory, valid_df, df_add_data=df_add_data, all_transformations=all_transforms) #train_transformations=all_transforms,\n",
    "\n",
    "\n",
    "# sampler\n",
    "train_sampler = generate_sampler(data_train)\n",
    "valid_sampler = generate_sampler(data_valid)\n",
    "# loaders\n",
    "train_loader = DataLoader(data_train,\n",
    "                         batch_size=batch_size,\n",
    "                         sampler=train_sampler,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=True)\n",
    "\n",
    "valid_loader = DataLoader(data_valid,\n",
    "                         batch_size=batch_size,\n",
    "                         sampler=valid_sampler,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9be74e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b66241",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get sample\n",
    "sample = data_train[0]\n",
    "# build model\n",
    "model = Net(sample, [8, 16, 32, 64, 128])\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"To cuda\")\n",
    "#     model.cuda()\n",
    "model.summary(batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27816173",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# record losses\n",
    "train_losses = dict()\n",
    "test_losses = dict()\n",
    "\n",
    "# callbacks\n",
    "ES = EarlyStopping(patience=5)\n",
    "MC = ModelCheckpoint()\n",
    "\n",
    "print(\"Beginning of the training\")\n",
    "\n",
    "# training\n",
    "for epoch in range(2):\n",
    "    update_dict(train_losses, train(epoch, model, optimizer, train_loader, to_cuda=True))\n",
    "    update_dict(test_losses, test(model, valid_loader, to_cuda=True, rescaling=stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ff3f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k in range(1,5):\n",
    "    print(np.linalg.norm(getattr(getattr(model,'branch' + str(k)), 'b' + str(k) + '-conv').weight.grad.data.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c3703",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loss visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08832b",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_losses(dict_losses, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot the different losses.\n",
    "    \n",
    "    Args:\n",
    "        dict_losses: dictionnary of losses\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    for key in dict_losses.keys():\n",
    "        plt.plot(dict_losses[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_tensor(X):\n",
    "    x = np.transpose(X[0], (1,2,0))\n",
    "    x = (x-x.min())/x.max()\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb76b5b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metric_path = 'results/models/model_5/'\n",
    "\n",
    "train_metrics = pd.read_csv(metric_path + 'train_losses.csv')\n",
    "test_metrics = pd.read_csv(metric_path + 'val_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d51b84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_losses(train_metrics[['disease']], \"Training losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f6ecb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_losses(test_metrics[['disease']], \"Val losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cce37e",
   "metadata": {},
   "source": [
    "## Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93691a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "args['dataset'] = 'val'\n",
    "args['preprocessing'] = 't1-linear'\n",
    "args['convolutions'] = [8,16,32,64,128]\n",
    "args['dropout'] = 0.2\n",
    "args['model_path'] = 'results/models/model_85'\n",
    "\n",
    "\n",
    "caps_directory = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021/'\n",
    "path = 'results/models/model_85/'\n",
    "training_df = pd.read_csv(os.path.join(args['model_path'], 'training_df.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(args['model_path'], 'valid_df.csv'))\n",
    "\n",
    "# get transformations\n",
    "train_transforms, all_transforms = get_transforms('image', minmaxnormalization=True, data_augmentation=None)\n",
    "\n",
    "# fetch volumetric data (useless in practice)\n",
    "stds, df_add_data = fetch_add_data(training_df)\n",
    "\n",
    "# build data loader\n",
    "if args['dataset'] == 'train':\n",
    "    data_loader = MRIDatasetImage(caps_directory, training_df, df_add_data=df_add_data,\n",
    "                                  preprocessing=args['preprocessing'], all_transformations=all_transforms)\n",
    "elif args['dataset'] == 'val':\n",
    "    data_loader = MRIDatasetImage(caps_directory, valid_df, df_add_data=df_add_data, preprocessing=args['preprocessing'],\n",
    "                                  all_transformations=all_transforms)\n",
    "else:\n",
    "    raise Exception('No dataset.')\n",
    "\n",
    "# get sample\n",
    "sample = data_loader[0]\n",
    "# build model\n",
    "model = Net(sample, args['convolutions'], args['dropout'], False).cuda()\n",
    "# load pretrained weights on validation set\n",
    "saved_data = torch.load(os.path.join(args['model_path'], 'test_best_model.pt'))\n",
    "model.load_state_dict(saved_data['model_state_dict'])\n",
    "\n",
    "# initialize interpretability method\n",
    "GC = GradCam(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e021030",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00eba71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = data_train[0]\n",
    "img = sample['image'].float()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37b136",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "saved_data = torch.load(os.path.join(path, 'test_best_model.pt'))\n",
    "\n",
    "model.load_state_dict(saved_data['model_state_dict'])\n",
    "\n",
    "# select one image\n",
    "img = sample['image'].float()\n",
    "\n",
    "mode = 'cuda'\n",
    "if mode == 'cuda':\n",
    "    model = model.cuda()\n",
    "    img = img.cuda()\n",
    "else:\n",
    "    model = model.cpu()\n",
    "    img = img.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83d9d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar = np.load('results/models/model_19/attribution_maps/GC/val/age/sub-ADNI002S1018_ses-M00.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bda604",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loss visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a8726",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saved_data = torch.load('results/models/model_19/last_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba39a1f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saved_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47e586",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_metrics = saved_data['val_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124cbad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_metrics['b3_MeanSquaredError']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd877ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_metrics)['b3_MeanSquaredError'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7496f0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Guided Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb3ab1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GBP = GuidedBackprop(model)\n",
    "attention_maps = GBP.generate_gradients(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55feea14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_explanations(img.cpu(), attention_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbf4a1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f2de9",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a0 = time.time()\n",
    "GC = GradCam(model)\n",
    "img = sample['image']\n",
    "attentions = GC.get_explanations(img.cuda(), resize=False, to_cpu=True)\n",
    "print(time.time() - a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97343c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a0 = time.time()\n",
    "model.cuda()\n",
    "GC = GradCam(model)\n",
    "img = data_loader[1]['image']\n",
    "attentions = GC.generate_cam(img.cuda(), branch='branch1', resize=True, to_cpu=True)\n",
    "print(time.time() - a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f71c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_explanations(img, {'branch1':attentions}, targets='disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c11aca",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for key in attentions:\n",
    "#     attentions[key] = attentions[key].cpu()\n",
    "visualize_explanations(img, attentions) #, targets='volumes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b69953",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a0 = time.time()\n",
    "GC = GradCam(model.cuda(), target_layer='conv2')\n",
    "img = sample['image'].float()\n",
    "attentions = GC.get_explanations(img.cuda(), resize=True, to_cpu=True)\n",
    "print(time.time() - a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca37236",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_explanations(img, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab791723",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_explanations(img, attentions, targets='disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6006ddc6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### max-sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62552349",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a,b,c,d = [], [], [], []\n",
    "n_max = 500\n",
    "step = 20\n",
    "for k in tqdm(range(1, n_max, step)):\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    resu = max_sensitivity(img, GC, k)\n",
    "    a.append(resu['branch1'])\n",
    "    b.append(resu['branch2'])\n",
    "    c.append(resu['branch3'])\n",
    "    d.append(resu['branch4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca86141",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "max_sensitivity(img, GC, N=1)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ed76d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for elem in (a, b, c ,d):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(1,n_max,step), elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7be98",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MoRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d3410",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attention = attentions['branch1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8e733",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ids = np.unravel_index(np.argsort(-attention, axis=None), attention.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c76b26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "group_size = 20000\n",
    "batch_X = torch.tile(img[None,...], (batch_size,1,1,1,1))\n",
    "for k in range(1, batch_size):\n",
    "    index = k*group_size\n",
    "    batch_X[k,0,ids[0][:index], ids[1][:index], ids[2][:index]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715326f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2 = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e5b58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resu = model2(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a2c89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = sample['image'].float()\n",
    "np.prod(img.shape)//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde01433",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MoRF(X, model, exp_method, K=None, group_size=20000, AUC=False, batch_size=16, to_cuda=False):\n",
    "    \"\"\"\n",
    "    Most relevant first: measures the reliability of an explanation by testing \n",
    "    how fast the output decreases, while we progressively remove information (e.g., perturb pixels) \n",
    "    from the input 𝑥𝑥 (e.g., image), that appears as the most relevant by the explanation.\n",
    "    Args:\n",
    "        X: tensor, brain image, with shape (1, n_channels, depth, height, width). The two first dimensions\n",
    "            are optional.\n",
    "        exp_method: explanation method. Must have a get_explanations(self, input_image) attribute function\n",
    "            which takes an image as input and returns a dictionary mapping branches to explanation maps\n",
    "        K: number of group of relevant pixels to remove\n",
    "        group_size: int, size of a group of pixels to remove\n",
    "        AUC: bool. If True: compute and return area under the curve obtained after removing successively \n",
    "            the K most relevant pixels.\n",
    "        batch_size: int, number of images passed to the model each time\n",
    "            \n",
    "    TO DO:\n",
    "        - add several methods to perturb pixels\n",
    "    \"\"\"\n",
    "    if to_cuda and torch.cuda.is_available():\n",
    "        X = X.cuda()\n",
    "        \n",
    "    if K is None:\n",
    "        K = np.prod(X.shape)//8\n",
    "    \n",
    "    # reshpae X if necessary\n",
    "    while len(X.shape) < 5:\n",
    "        X = X[None,...]\n",
    "    \n",
    "    # original predictions\n",
    "    preds = model(X)\n",
    "    # explanations for original image\n",
    "    expls = exp_method.get_explanations(X, resize=True)\n",
    "    # explanations for new images\n",
    "    new_preds = dict()\n",
    "    \n",
    "    # def update_dict\n",
    "    \n",
    "    for target in expls:\n",
    "        # Indices of the sorted elements of the explanations:\n",
    "        ids = np.unravel_index(np.argsort(-expls[target], axis=None), expls[target].shape)\n",
    "    \n",
    "        if AUC:\n",
    "            # number of \n",
    "            removed_pixels = 0\n",
    "            while removed_pixels < K:\n",
    "                # create batch of images\n",
    "                bs = min(batch_size,(K - removed_pixels)%group_size)\n",
    "                batch_X = torch.tile(X, (bs,1,1,1,1))\n",
    "                for k in range(1, batch_size):\n",
    "                    index = k*group_size\n",
    "                    batch_X[k,0,ids[0][:index], ids[1][:index], ids[2][:index]] = 0\n",
    "                    new_preds[target] = model(batch_X)\n",
    "        else:\n",
    "            # compute MoRF removing the K most relevant pixels\n",
    "            batch_X = X.copy()\n",
    "            batch_X[0,0,ids[0][:K], ids[1][:K], ids[2][:K]]\n",
    "            new_preds[target] = model(batch_X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550cff1",
   "metadata": {},
   "source": [
    "### Explanations analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b31f0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.explanations.analysis.utils import *\n",
    "from tools.settings import *\n",
    "import nibabel as nib\n",
    "from tools.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ff994d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_tsv, atlas_map = load_atlas()\n",
    "atlas_tsv = pd.read_csv('atlas/atlas-AAL2_space-MNI152NLin2009cSym_dseg.csv')\n",
    "#atlas_tsv.roi_value = atlas_tsv.roi_value.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_map = np.load(os.path.join('results/models/model_85/attribution_maps/GC/val/age', 'sub-ADNI018S0425_ses-M00.npy'))\n",
    "#resized_att_map = zoom(att_map, atlas_map.shape/ np.array(att_map.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/9786102/how-do-i-parallelize-a-simple-python-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(data_path, atlas_tsv, atlas_map):\n",
    "    scores = {}\n",
    "    # fetch file names\n",
    "    files = [file for file in os.listdir(data_path) if os.path.splitext(file)[1] == '.npy']\n",
    "    for k, file in tqdm(enumerate(files)):\n",
    "        # load attention map\n",
    "        att_map = np.load(os.path.join(data_path, file))\n",
    "        # compute region scores\n",
    "        scores[file] = region_scores(att_map, atlas_tsv, atlas_map, resize=True)\n",
    "        if k == 2:\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfe72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_scores('results/models/model_85/attribution_maps/GC/val/age', atlas_tsv, atlas_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: check if no attention map has NaNs\n",
    "counter = 0\n",
    "data_path = 'results/models/model_85/attribution_maps/GC/val/disease'\n",
    "files = [file for file in os.listdir(data_path) if os.path.splitext(file)[1] == '.npy']\n",
    "for k, file in tqdm(enumerate(files)):\n",
    "    map_ = np.load(os.path.join(data_path, file))\n",
    "    nans = np.isnan(map_).sum()\n",
    "    if nans>0:\n",
    "        counter+=1\n",
    "        \n",
    "print(counter/len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_tsv['roi_name'][np.argsort(-importances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cf863a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = np.load(\"/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/model_85/predictions/test/age.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c39f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns(index):\n",
    "    l = []\n",
    "    for k in range(4,len(index)):\n",
    "        l.append(index[k].split('ROI')[1])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6913f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 -Cerebelum_Crus1_L__intensity -Cerebelum_Crus1_L_intensity\n",
      "102 -Cerebelum_6_L_intensity -Cerebelum_6_L_9_intensity\n"
     ]
    }
   ],
   "source": [
    "l1 = check_columns(raw_target_df.columns)\n",
    "l2 = check_columns(raw_target_df2.columns)\n",
    "for k in range(len(l1)):\n",
    "    if l1[k] != l2[k]:\n",
    "        print(k, l1[k], l2[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89dc28",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a1bc3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses = pd.read_csv('train_losses_3D_2.csv')\n",
    "test_losses = pd.read_csv('val_losses_3D_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65649095",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f319ae7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(test_losses[['disease', 'volumes', 'age', 'sex']])\n",
    "plt.ylim([0,150])\n",
    "plt.legend(['disease', 'volumes', 'age', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991ce04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses[['disease', 'volumes', 'age', 'sex']])\n",
    "plt.legend(['disease', 'volumes', 'age', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09078e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "from torchmetrics import MetricCollection, Accuracy, Precision, Recall\n",
    "target = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1])\n",
    "preds = torch.tensor([1, 1, 1, 0, 1, 1, 1, 1])\n",
    "metrics = MetricCollection([Accuracy(),\n",
    "                            Precision(num_classes=2, average='micro'),\n",
    "                            Recall(num_classes=3, average='macro')])\n",
    "metrics(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d00a1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# assess gradient norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a728b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4813001",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_gradient_norms(model): \n",
    "    path = 'results/models/model_{}/log.out'.format(model)\n",
    "    \n",
    "    file = None\n",
    "    with open(path, 'r') as f:\n",
    "        file = f.read()\n",
    "\n",
    "    data = [ s[36:] for s in file.split('\\n') if 'STDOUT' in s]\n",
    "    data = [ s for k,s in enumerate(data[1:]) if data[k] == 'GRADIENT']\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "def compute_metrics(data, name):\n",
    "    dict_ = {'mean': data.mean(),\n",
    "             'min': data.min(),\n",
    "             'max': data.max(), \n",
    "             'std': data.std(), \n",
    "             'median': np.median(data)}\n",
    "    return pd.DataFrame(dict_, index=[name])\n",
    "\n",
    "def get_all_metrics():\n",
    "    df = None\n",
    "    for k in range(4):\n",
    "        data = get_gradient_norms(9+k)\n",
    "        if df is None:\n",
    "            df = compute_metrics(data,BRANCH2TARGET['branch' + str(k+1)])\n",
    "        else:\n",
    "            df = df.combine_first(compute_metrics(data,BRANCH2TARGET['branch' + str(k+1)]))\n",
    "    return df\n",
    "\n",
    "def plot_training(model):\n",
    "    fig, ax = plt.subplots(1,4,figsize=(16,4))\n",
    "    for k, target in enumerate(TARGET2BRANCH):\n",
    "        df_train = pd.read_csv('results/models/model_{}/train_losses.csv'.format(model))\n",
    "        df_val = pd.read_csv('results/models/model_{}/val_losses.csv'.format(model))\n",
    "        ax[k].plot(getattr(df_train, target), label='train')\n",
    "        ax[k].plot(getattr(df_val, target), label='val')\n",
    "        ax[k].set_title(target)\n",
    "    plt.legend()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d09e46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = get_all_metrics()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707fc1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights = (1/df['mean']).to_numpy()\n",
    "weights = weights/weights.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4639e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_training(model=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996e6bb",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('results/models/model_{}/val_losses.csv'.format(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c05fa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7020e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "absolute_path = '/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models'\n",
    "models = ['model_' + str(k) for k in range(21, 25)]\n",
    "models = ['model_' + str(k) for k in [70, 73, 75, 76]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af67bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(os.path.join(absolute_path, model, 'gradient_norms.csv')) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee98b80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "norms = pd.concat(dfs, axis=1)\n",
    "for key in TARGET2BRANCH.keys():\n",
    "    norms.rename(columns={'gradient_norms_' + key: key}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707145dd",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = norms.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c6c60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats.loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1d4a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_norms = norms.rolling(window=153).mean()[0::153]\n",
    "scaled_avg_norms = avg_norms/stats.loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba65f33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_norms.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb1b2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaled_avg_norms.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03dd43",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale_parameters = 1/stats.loc['mean']\n",
    "scale_parameters = scale_parameters/scale_parameters.sum()*4\n",
    "scale_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebec180",
   "metadata": {
    "hidden": true
   },
   "source": [
    "nohup python training.py -bs 16 -lw 1.054807 1.607432 0.370006 0.967756 -d 0.2 &\n",
    "nohup python training.py -e 100 --patience 100 -bs 16 -d 0.5 -lwp results/models/loss_weights.npy &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0e571",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loss_weights = np.array([1.054807, 1.607432, 0.370006, 0.967756])\n",
    "loss_weights = scale_parameters.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673dfc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('results/models/loss_weights_t1l_without_bn.npy', loss_weights.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9f97d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Age investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f54fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([training_df, valid_df], ignore_index=True)\n",
    "df2 = df_add_data.merge(df, on =['participant_id', 'session_id'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c7107",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.title('Age Distribution')\n",
    "plt.hist(training_df.age, label='training')\n",
    "plt.hist(valid_df.age, label='validation')\n",
    "plt.xlabel('age')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d71685",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Results investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064b625",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "absolute_path = '/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models'\n",
    "models = [ model for model in os.listdir(absolute_path) if 'model' in model ]\n",
    "dicts = []\n",
    "for model in models:\n",
    "    f = open(os.path.join(absolute_path, model, 'commandline.json'),)\n",
    "    d = json.load(f)\n",
    "    d.update({'model': int(model[6:])})\n",
    "    dicts.append(d)\n",
    "parameters = pd.DataFrame(dicts)\n",
    "parameters.sort_values('model', inplace=True)\n",
    "parameters.to_csv('results/models/summary.csv', index=False)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17ed8f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf5624",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9ff1cae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_performances(models):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        - models: list of ints (model numbers)\n",
    "    \"\"\"\n",
    "    if type(models) != list:\n",
    "        models = [models]\n",
    "    \n",
    "    best_performances = pd.DataFrame({'model': []})\n",
    "    for model in models:\n",
    "        try:\n",
    "            performances = pd.read_csv('results/models/model_{}/test_metrics.csv'.format(model))\n",
    "        except:\n",
    "            saved_data = torch.load('results/models/model_{}/last_model.pt'.format(model))\n",
    "            performances = pd.DataFrame(saved_data['val_metrics'])\n",
    "        best_performances = best_performances.append(performances[performances.test == performances.test.min()])\n",
    "    best_performances.reset_index(inplace=True)\n",
    "    #best_performances.drop(columns=['index'], inplace=True)\n",
    "    best_performances['model'] = models\n",
    "    return best_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec8e6005",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>disease</th>\n",
       "      <th>volumes</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test</th>\n",
       "      <th>b1_Accuracy</th>\n",
       "      <th>b1_F1</th>\n",
       "      <th>b1_AUROC</th>\n",
       "      <th>b2_MeanSquaredError</th>\n",
       "      <th>b2_R2Score</th>\n",
       "      <th>b3_MeanSquaredError</th>\n",
       "      <th>b3_R2Score</th>\n",
       "      <th>b4_Accuracy</th>\n",
       "      <th>b4_F1</th>\n",
       "      <th>b4_AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>72</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>0.221217</td>\n",
       "      <td>0.173681</td>\n",
       "      <td>0.052454</td>\n",
       "      <td>0.538274</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.946354</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.341011</td>\n",
       "      <td>5.832608</td>\n",
       "      <td>0.326477</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.990303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "      <td>0.100209</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.176956</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.459013</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.936458</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>5.887350</td>\n",
       "      <td>0.313775</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.991861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>0.087246</td>\n",
       "      <td>0.252608</td>\n",
       "      <td>0.187973</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.930035</td>\n",
       "      <td>0.055642</td>\n",
       "      <td>0.247357</td>\n",
       "      <td>6.067847</td>\n",
       "      <td>0.271053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.990823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>0.099093</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.054445</td>\n",
       "      <td>0.277635</td>\n",
       "      <td>6.318741</td>\n",
       "      <td>0.209525</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.993420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>0.237659</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.532610</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.930382</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.291082</td>\n",
       "      <td>5.651477</td>\n",
       "      <td>0.367660</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.990649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>0.229576</td>\n",
       "      <td>0.184643</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>0.551193</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.832117</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.314953</td>\n",
       "      <td>6.013856</td>\n",
       "      <td>0.283967</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.989437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>0.230539</td>\n",
       "      <td>0.181573</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.591986</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.312330</td>\n",
       "      <td>5.963646</td>\n",
       "      <td>0.295874</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>85</td>\n",
       "      <td>0.116838</td>\n",
       "      <td>0.210712</td>\n",
       "      <td>0.177086</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.461780</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.921528</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.371804</td>\n",
       "      <td>5.889508</td>\n",
       "      <td>0.313272</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.993420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  model   disease   volumes       age       sex      test  \\\n",
       "0     20     72  0.090923  0.221217  0.173681  0.052454  0.538274   \n",
       "1     17     77  0.100209  0.226368  0.176956  0.032029  0.459013   \n",
       "2     13     78  0.087246  0.252608  0.187973  0.041201  0.493580   \n",
       "3     13     79  0.099093  0.242389  0.203839  0.027808  0.478227   \n",
       "4     53     80  0.097928  0.237659  0.163061  0.033962  0.532610   \n",
       "5      6     81  0.103611  0.229576  0.184643  0.033362  0.551193   \n",
       "6     70     83  0.172959  0.230539  0.181573  0.006916  0.591986   \n",
       "7     51     85  0.116838  0.210712  0.177086  0.034424  0.461780   \n",
       "\n",
       "   b1_Accuracy     b1_F1  b1_AUROC  b2_MeanSquaredError  b2_R2Score  \\\n",
       "0     0.888158  0.888889  0.946354             0.051961    0.341011   \n",
       "1     0.894737  0.888889  0.936458             0.052569    0.325496   \n",
       "2     0.868421  0.864865  0.930035             0.055642    0.247357   \n",
       "3     0.855263  0.842857  0.903472             0.054445    0.277635   \n",
       "4     0.855263  0.857143  0.930382             0.053951    0.291082   \n",
       "5     0.848684  0.832117  0.912326             0.053112    0.314953   \n",
       "6     0.526316  0.000000  0.500000             0.053107    0.312330   \n",
       "7     0.842105  0.844156  0.921528             0.050627    0.371804   \n",
       "\n",
       "   b3_MeanSquaredError  b3_R2Score  b4_Accuracy     b4_F1  b4_AUROC  \n",
       "0             5.832608    0.326477     0.934211  0.933333  0.990303  \n",
       "1             5.887350    0.313775     0.953947  0.954839  0.991861  \n",
       "2             6.067847    0.271053     0.934211  0.933333  0.990823  \n",
       "3             6.318741    0.209525     0.947368  0.948718  0.993420  \n",
       "4             5.651477    0.367660     0.960526  0.960526  0.990649  \n",
       "5             6.013856    0.283967     0.947368  0.948052  0.989437  \n",
       "6             5.963646    0.295874     0.986842  0.986842  1.000000  \n",
       "7             5.889508    0.313272     0.953947  0.955414  0.993420  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = get_performances([72, 77, 78, 79, 80, 81, 83, 85])\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b20b8e4d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf['R2Score'] = perf['b2_R2Score'] + perf['b3_R2Score']\n",
    "perf['total_test'] = perf['disease'] + perf['volumes'] + perf['age'] + perf['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a77920",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>disease</th>\n",
       "      <th>volumes</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test</th>\n",
       "      <th>b1_Accuracy</th>\n",
       "      <th>b1_F1</th>\n",
       "      <th>b1_AUROC</th>\n",
       "      <th>b2_MeanSquaredError</th>\n",
       "      <th>b2_R2Score</th>\n",
       "      <th>b3_MeanSquaredError</th>\n",
       "      <th>b3_R2Score</th>\n",
       "      <th>b4_Accuracy</th>\n",
       "      <th>b4_F1</th>\n",
       "      <th>b4_AUROC</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>total_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>72</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>0.221217</td>\n",
       "      <td>0.173681</td>\n",
       "      <td>0.052454</td>\n",
       "      <td>0.538274</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.946354</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.341011</td>\n",
       "      <td>5.832608</td>\n",
       "      <td>0.326477</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.990303</td>\n",
       "      <td>0.667488</td>\n",
       "      <td>0.538274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "      <td>0.100209</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.176956</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.459013</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.936458</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>5.887350</td>\n",
       "      <td>0.313775</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>0.087246</td>\n",
       "      <td>0.252608</td>\n",
       "      <td>0.187973</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.930035</td>\n",
       "      <td>0.055642</td>\n",
       "      <td>0.247357</td>\n",
       "      <td>6.067847</td>\n",
       "      <td>0.271053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.990823</td>\n",
       "      <td>0.518409</td>\n",
       "      <td>0.569029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>0.099093</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.203839</td>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.478227</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.054445</td>\n",
       "      <td>0.277635</td>\n",
       "      <td>6.318741</td>\n",
       "      <td>0.209525</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.993420</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>0.237659</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.532610</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.930382</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.291082</td>\n",
       "      <td>5.651477</td>\n",
       "      <td>0.367660</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.990649</td>\n",
       "      <td>0.658741</td>\n",
       "      <td>0.532610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>0.229576</td>\n",
       "      <td>0.184643</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>0.551193</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.832117</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.314953</td>\n",
       "      <td>6.013856</td>\n",
       "      <td>0.283967</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.598920</td>\n",
       "      <td>0.551193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>0.230539</td>\n",
       "      <td>0.181573</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.591986</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.312330</td>\n",
       "      <td>5.963646</td>\n",
       "      <td>0.295874</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608203</td>\n",
       "      <td>0.591986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>85</td>\n",
       "      <td>0.116838</td>\n",
       "      <td>0.210712</td>\n",
       "      <td>0.177086</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.461780</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.921528</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.371804</td>\n",
       "      <td>5.889508</td>\n",
       "      <td>0.313272</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.993420</td>\n",
       "      <td>0.685075</td>\n",
       "      <td>0.539059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  model   disease   volumes       age       sex      test  \\\n",
       "0     20     72  0.090923  0.221217  0.173681  0.052454  0.538274   \n",
       "1     17     77  0.100209  0.226368  0.176956  0.032029  0.459013   \n",
       "2     13     78  0.087246  0.252608  0.187973  0.041201  0.493580   \n",
       "3     13     79  0.099093  0.242389  0.203839  0.027808  0.478227   \n",
       "4     53     80  0.097928  0.237659  0.163061  0.033962  0.532610   \n",
       "5      6     81  0.103611  0.229576  0.184643  0.033362  0.551193   \n",
       "6     70     83  0.172959  0.230539  0.181573  0.006916  0.591986   \n",
       "7     51     85  0.116838  0.210712  0.177086  0.034424  0.461780   \n",
       "\n",
       "   b1_Accuracy     b1_F1  b1_AUROC  b2_MeanSquaredError  b2_R2Score  \\\n",
       "0     0.888158  0.888889  0.946354             0.051961    0.341011   \n",
       "1     0.894737  0.888889  0.936458             0.052569    0.325496   \n",
       "2     0.868421  0.864865  0.930035             0.055642    0.247357   \n",
       "3     0.855263  0.842857  0.903472             0.054445    0.277635   \n",
       "4     0.855263  0.857143  0.930382             0.053951    0.291082   \n",
       "5     0.848684  0.832117  0.912326             0.053112    0.314953   \n",
       "6     0.526316  0.000000  0.500000             0.053107    0.312330   \n",
       "7     0.842105  0.844156  0.921528             0.050627    0.371804   \n",
       "\n",
       "   b3_MeanSquaredError  b3_R2Score  b4_Accuracy     b4_F1  b4_AUROC   R2Score  \\\n",
       "0             5.832608    0.326477     0.934211  0.933333  0.990303  0.667488   \n",
       "1             5.887350    0.313775     0.953947  0.954839  0.991861  0.639271   \n",
       "2             6.067847    0.271053     0.934211  0.933333  0.990823  0.518409   \n",
       "3             6.318741    0.209525     0.947368  0.948718  0.993420  0.487160   \n",
       "4             5.651477    0.367660     0.960526  0.960526  0.990649  0.658741   \n",
       "5             6.013856    0.283967     0.947368  0.948052  0.989437  0.598920   \n",
       "6             5.963646    0.295874     0.986842  0.986842  1.000000  0.608203   \n",
       "7             5.889508    0.313272     0.953947  0.955414  0.993420  0.685075   \n",
       "\n",
       "   total_test  \n",
       "0    0.538274  \n",
       "1    0.535562  \n",
       "2    0.569029  \n",
       "3    0.573129  \n",
       "4    0.532610  \n",
       "5    0.551193  \n",
       "6    0.591986  \n",
       "7    0.539059  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769facb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = 'model_72'\n",
    "train_csv = pd.read_csv('results/models/{}/train_metrics.csv'.format(model))\n",
    "val_csv = pd.read_csv('results/models/{}/test_metrics.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3178c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_csv['test'].plot()\n",
    "train_csv['train'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdee562",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val = pd.read_csv('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/model_19/test_metrics.csv')\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff4762",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val[val.test == val.test.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19bc16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val[val.test == val.test.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb9330",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val[val.test == val.test.min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d606636",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18da0ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#path = 'network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/model_32'\n",
    "model = 'model_26'\n",
    "training_df = pd.read_csv('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/{}/training_df.csv'.format(model))\n",
    "valid_df = pd.read_csv('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/{}/valid_df.csv'.format(model))\n",
    "\n",
    "train_transforms, all_transforms = get_transforms('image', minmaxnormalization=True, data_augmentation=None)\n",
    "# fetch volumetric data\n",
    "stds, df_add_data = fetch_add_data(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfb00b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "caps_directory = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021/'\n",
    "# build MRI datasets\n",
    "data_train = MRIDatasetImage(caps_directory, training_df, df_add_data=df_add_data, preprocessing='t1-volume',\n",
    "                             all_transformations=all_transforms)  # train_transformations=all_transforms\n",
    "data_valid = MRIDatasetImage(caps_directory, valid_df, df_add_data=df_add_data, preprocessing='t1-volume',\n",
    "                             all_transformations=all_transforms)  # train_transformations=all_transforms,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1ef9b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "valid_loader = DataLoader(data_valid,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=8,\n",
    "                          pin_memory=True)\n",
    "\n",
    "train_loader = DataLoader(data_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=8,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8db73",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = 'model_26'\n",
    "saved_data = torch.load(os.path.join('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/' + model, 'last_model.pt'))\n",
    "# get sample\n",
    "sample = data_train[0]\n",
    "# build model\n",
    "model = Net(sample, [8, 16, 32, 64, 128], 0.3).cuda()\n",
    "# load pretrained weights on validation set\n",
    "# saved_data = torch.load(os.path.join(args.model_path, 'test_best_model.pt'))\n",
    "model.load_state_dict(saved_data['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b62c31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a154de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca88ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resu = test(model,\n",
    "     valid_loader,\n",
    "     loss_weights= [1, 1, 1, 1], #np.array([1.054807, 1.607432, 0.370006, 0.967756]),\n",
    "     to_cuda=True,\n",
    "     rescaling=stds,\n",
    "     compute_metrics=True,\n",
    "     eval_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d81e20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f5915",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saved_data = torch.load(os.path.join('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/' + 'model_63', 'last_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a33fe4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(saved_data['train_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda74480",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## investigating df_add_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b27b65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021.tsv'\n",
    "summary_path = '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021_summary.tsv'\n",
    "\n",
    "# fetch indexes\n",
    "df_summary = pd.read_csv(summary_path, sep='\\t')\n",
    "df_summary = df_summary[(df_summary.pipeline_name == pipeline_name) & (df_summary.atlas_id == atlas_id)]\n",
    "first_column_name = df_summary.first_column_name.item()\n",
    "last_column_name = df_summary.last_column_name.item()\n",
    "print('First column name: ', first_column_name)\n",
    "print('Last column name: ', last_column_name)\n",
    "df_data = pd.read_csv(data_path, sep='\\t', nrows=1)\n",
    "first_column_index = df_data.columns.get_loc(first_column_name)\n",
    "last_column_index = df_data.columns.get_loc(last_column_name)\n",
    "\n",
    "# other data to fetch\n",
    "col_names = ['participant_id', 'session_id', 'sex', 'age']\n",
    "add_indexes = [df_data.columns.get_loc(col_name) for col_name in col_names]\n",
    "\n",
    "# compute df_add_data\n",
    "# add 1 to first_column_index to ignore background\n",
    "used_columns = np.hstack([add_indexes, np.arange(first_column_index + 1, last_column_index + 1)]).flatten()\n",
    "df_add_data = pd.read_csv(data_path, sep='\\t', usecols=used_columns).dropna(axis=0, how='any')\n",
    "print(df_add_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94dbfa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# normalization using only statistics from training data\n",
    "temp_df = pd.merge(training_data[['participant_id', 'session_id']],\n",
    "                   df_add_data, on=['participant_id', 'session_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4bd35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scalar_cols = [col for col in temp_df.columns if col not in ['participant_id', 'session_id', 'sex']]\n",
    "# df_add_data[scalar_cols] contains only scalar columns with (patient, session) from training set\n",
    "means, stds = temp_df[scalar_cols].mean(), temp_df[scalar_cols].std()\n",
    "df_add_data[scalar_cols] = (df_add_data[scalar_cols] - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee23d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_add_data[scalar_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa03385",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/model_39/train_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a086874",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('/network/lustre/dtlake01/aramis/users/sasha.collin/interpretability-dl-ndd/results/models/model_39/test_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aac055",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d193995",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'results/models'\n",
    "model_numbers = np.arange(47, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174288e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(os.path.join(path, 'model_' + str(k), 'test_metrics.csv')) for k in model_numbers]\n",
    "dfs_train = [pd.read_csv(os.path.join(path, 'model_' + str(k), 'train_metrics.csv')) for k in model_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b53bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k in range(4):\n",
    "    print(dfs_train[k]['train'].min(), dfs_train[k]['b2_R2Score'].max(), dfs_train[k]['b3_R2Score'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbcdf1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k in range(4):\n",
    "    print(dfs[k]['test'].min(), dfs[k]['b2_R2Score'].max(), dfs[k]['b3_R2Score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217f5be",
   "metadata": {},
   "source": [
    "# AIBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab63037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99854d6c",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cbb3a",
   "metadata": {},
   "source": [
    "I am using working with the file '/network/lustre/dtlake01/aramis/datasets/adni/caps/caps_v2021.tsv' and using the 't1-volume' pipeline and the atlas 'AAL2'.\n",
    "6267 samples (i.e. couples (participant_id, session_id)) do not have any volume value (i.e. NaN). 1 sample has no sex value and 1178 samples have no age values.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
